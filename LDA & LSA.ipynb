{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adabc35c-4e53-4693-8582-5a64dcb2efa7",
   "metadata": {},
   "source": [
    "**Topic Modeling on News Articles using LDA & LSA (Gensim)**\n",
    "\n",
    "This script performs topic modeling on news article content using two unsupervised learning methods: LDA (Latent Dirichlet Allocation) and LSA (Latent Semantic Analysis). It includes text preprocessing (cleaning, stopword removal, tokenization, stemming), vectorization using Bag of Words, topic extraction, and coherence score evaluation to determine the optimal number of topics.\n",
    "\n",
    "Main steps:\n",
    "\n",
    "Load and clean the text data\n",
    "\n",
    "Remove stopwords, tokenize, and stem words\n",
    "\n",
    "Convert text into bag-of-words representation\n",
    "\n",
    "Train LDA and LSA models to extract topics\n",
    "\n",
    "Evaluate LSA coherence scores and visualize topic quality\n",
    "\n",
    "Print top terms per topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3e419-9341-4fa7-bd2a-b036cf4c9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2efad-e97c-4eb3-bb68-6f57c71690b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d4d4-0c5e-4d91-8943-8307029525d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda48491-ca0c-41f4-ba10-2f632a913190",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ebebc-1d13-490e-a1cd-bc35588d5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50cad14-6fd4-4422-b824-1c5bbc05ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561dcf6-f86d-4193-b551-0049f1ddaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce70ce0-e2ea-4c09-ab0d-a25b267d92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preparation\n",
    "\n",
    "#lowercasing\n",
    "articles = articles.str.lower().apply(lambda x: re.sub(r\"([^\\w\\s])\", \"\", x))\n",
    "\n",
    "# stop words removal\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "articles = articles.apply(lambda x: ' '.join([word for word in x.split() if word not in (en_stopwords)]))\n",
    "\n",
    "# tokenize\n",
    "articles = articles.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "#stemming (done for speed as we have a lot of text)\n",
    "ps = PorterStemmer()\n",
    "articles = articles.apply( lambda tokens: [ps.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6e349-57de-404f-a371-b842e3c82aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53d681-af87-4b13-bf64-231670354130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "dictionary = corpora.Dictionary(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc24c0-7902-4975-8bbe-c660d6370e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8deb5ad-07e3-4515-915a-b37c8c1b8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing\n",
    "doc_term = [dictionary.doc2bow(text) for text in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6c919-caaa-4b68-9809-18c3cd42a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef874c2-0c7b-4955-905b-9082f66b0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Model (2 topics)\n",
    "\n",
    "num_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00647e08-3730-4fe7-a59c-5d653d4ff7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09998b-1555-4966-b786-4976379c04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus = doc_term,\n",
    "                                 id2word = dictionary,\n",
    "                                 num_topics = num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f691bb2-d87f-41bc-a40d-a1bae9aa58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA Model (2 topics)\n",
    "\n",
    "lda_model.print_topics(num_topics=num_topics, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3155db-277b-4795-93a7-28bb826532fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb7550-5d2f-42dd-921a-ed78471be7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model = LsiModel(corpus=doc_term, id2word=dictionary, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3056c-3c1b-4a35-94c7-1ecaf59e677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lsa_model.print_topics(num_topics=num_topics, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbfba7-1c72-452d-b31a-fb34a2ada047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aee70b-4c33-4a20-8edb-706c5f92e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coherence values for multiple topic numbers (2â€“11)\n",
    "\n",
    "coherence_values = []\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c6e0-7102-4013-8cbc-55bdd0e8c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_topics = 2\n",
    "max_topics = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631b572-3e26-484b-b15f-bcbf28edcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics_i in range(min_topics, max_topics+1):\n",
    "    model = LsiModel(doc_term, num_topics=num_topics_i, id2word = dictionary, random_seed=0)\n",
    "    model_list.append(model)\n",
    "    coherence_model = CoherenceModel(model=model, texts=articles, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherence_model.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10238f-a62b-4256-8928-06fbfc8319f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coherence values to find the optimal number of topics\n",
    "\n",
    "plt.plot(range(min_topics, max_topics+1), coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f17ba8-d28e-42e8-8448-12f488022ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final LSA Model with optimal topic number\n",
    "\n",
    "final_num_topics = 3\n",
    "final_lsa_model = LsiModel(corpus=doc_term, id2word=dictionary, num_topics=final_num_topics)\n",
    "print(final_lsa_model.print_topics(num_topics=final_num_topics, num_words=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
